Diabetic retinopathy (DR) is an eye disease triggered due to diabetes, which may lead to blindness. To prevent diabetic patients from becoming blind, early diagnosis and accurate detection of DR are vital. Deep learning models, such as convolutional neural networks (CNNs), are largely used in DR detection through the classification of blood vessel pixels from the remaining pixels.
The convolutional neural network (CNN) is one of the main models of deep learning used to detect, predict, and classify medical images. This project aims to detect DR by implementing the CNN model on the dataset.
The dataset is taken from Kaggle and consists of images of fundus of the eye. The dataset is divided into five classes of different five outputs. The model takes an input image and classifies the input image into one of the classes.
There are three main layers in the CNN architecture, which are convolution layers (CONV), pooling layers, and fully connected layers (FC). The number of layers, size, and the number of filters of the CNN vary according to the author's vision. Each layer in CNN architecture plays a specific role. In the CONV layers, different filters convolve an image to extract the features. Typically, pooling layer follows the CONV layer to reduce the dimensions of feature maps. There are many strategies for pooling but average pooling and max pooling are adopted most [15]. A FC layers are a compact feature to describe the whole input image. SoftMax activation function is the most used classification function.




The methodology used here is firstly we preprocess the fundus image of the eye and pass the image through the deep learning model which we have trained on the Diabetic Retinopathy 224x224 (2019 Data) dataset and classify the input image into one of the particular classes image.
3.1     Dataset Preprocessing And Loading
File Path Construction: Ensures images are located in the correct directory based on their labels.
File Existence Check: Handles cases where images might be missing, ensuring the program doesn't crash.
Image Loading and Resizing: Standardizes all images to a size of 224x224 pixels.
Normalization: Scales pixel values to the range [0, 1], which is beneficial for training neural networks.
Data Collection: Gathers the preprocessed images and labels for use in machine learning models.      
3.2 CNN Model Building and Training
Count Diagnosis Types:
It figures out how many different diagnosis types (classes) there are.
Convert Labels to One-Hot Encoding:
It changes the labels into a format that the neural network can understand, where each diagnosis type is represented as a binary vector.
Split Data:
It divides the images and labels into two sets: one for training (80% of the data) and one for validation (20% of the data). The training set is used to teach the model, and the validation set is used to see how well it is learning.
Build the Model:
The model is made up of several layers:
Conv2D and MaxPooling2D layers: These layers help the model learn features from the images, such as edges and textures, by applying filters and down-sampling.
Flatten layer: This layer converts the 2D data into 1D so it can be fed into fully connected layers.
Dense layer: This is a fully connected layer that helps in learning complex patterns.
Dropout layer: This layer randomly turns off some neurons during training to prevent overfitting (memorizing the training data too well and not generalizing to new data).
Output layer: The final layer uses a softmax activation to predict the probability of each class (diagnosis type).
Compile the Model:
It sets up the model with an optimizer (Adam), a loss function (categorical cross-entropy), and a metric (accuracy) to prepare it for training.
Train the Model:
It teaches the model using the training data for 10 rounds (epochs) and checks its performance on the validation data after each round.


Conclusion and Future Work 

We divide fundus images into classes face by using a deep morning model based on CNN Architecture with an accuracy of almost 80% trained on the Diabetic Retinopathy 224x224 (2019 Data) dataset. The result can be better and more accurate by some of following methods
1.	We can use some other model with combinations with the existing CNN Model like U-Net or Res Net for the DR Classification.
2.	The accuracy of model can be increased by increasing the layers in the convolutional neural network used or some other filters or it can be increased by use of more epochs as the model was trained on 10 due to lack of proper systems for training such a heavy model.
3.	The accuracy can be increased by takin a larger dataset, in our case the dataset is of small size, consisting of only 3,662 images in total
4.	A new dataset artificial dataset can be generated by the help of the Generative Adversarial Network (GAN).



